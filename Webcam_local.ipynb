{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EpiFgStk9sI"
      },
      "source": [
        "From Detectron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# ... your code to use the camera ...\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# When everything done, release the capture\u001b[39;00m\n\u001b[1;32m      4\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m----> 5\u001b[0m cv2\u001b[39m.\u001b[39;49mdestroyAllWindows()\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
          ]
        }
      ],
      "source": [
        "# ... your code to use the camera ...\n",
        "\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The directory /run/user/1000/gvfs/google-drive:host=gmail.com,user=omnidox05/0AI-koVAbJ8KdUk9PVA/1-2ZZmoG4LOv52yActwwW1J04u1OXIDDh/1-4Cy-PP5dxsMACkBWclLG7-S9yOYfvHr exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "export_dir = \"/run/user/1000/gvfs/google-drive:host=gmail.com,user=omnidox05/0AI-koVAbJ8KdUk9PVA/1-2ZZmoG4LOv52yActwwW1J04u1OXIDDh/1-4Cy-PP5dxsMACkBWclLG7-S9yOYfvHr\"  # replace with your actual path\n",
        "\n",
        "# Check if directory exists\n",
        "if os.path.isdir(export_dir):\n",
        "    print(f\"The directory {export_dir} exists.\")\n",
        "else:\n",
        "    print(f\"The directory {export_dir} does not exist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The file /run/user/1000/gvfs/google-drive:host=gmail.com,user=omnidox05/0AI-koVAbJ8KdUk9PVA/1-2ZZmoG4LOv52yActwwW1J04u1OXIDDh/1-4Cy-PP5dxsMACkBWclLG7-S9yOYfvHr/1jQm__EcHNAU-mw6peloqp4_-4wnyM3Fm/1-R2-ChXwMskc1ZAhz-V3zcV1DYpNjx49 exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "export_dir = \"/run/user/1000/gvfs/google-drive:host=gmail.com,user=omnidox05/0AI-koVAbJ8KdUk9PVA/1-2ZZmoG4LOv52yActwwW1J04u1OXIDDh/1-4Cy-PP5dxsMACkBWclLG7-S9yOYfvHr/1jQm__EcHNAU-mw6peloqp4_-4wnyM3Fm/1-R2-ChXwMskc1ZAhz-V3zcV1DYpNjx49\"\n",
        "\n",
        "# Check if the path points to a file\n",
        "if os.path.isfile(export_dir):\n",
        "    print(f\"The file {export_dir} exists.\")\n",
        "else:\n",
        "    print(f\"The file {export_dir} does not exist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xCYXOy_g2uh",
        "outputId": "1c371d52-bd12-4151-8cc8-26e008fac4fe"
      },
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d288Z2mF5dC",
        "outputId": "a68d538e-8862-4abe-c6b2-341cd992d75b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version:  2.0.1+cu118\n",
            "CUDA version:  11.8\n"
          ]
        }
      ],
      "source": [
        "import torch, detectron2\n",
        "\n",
        "print(\"PyTorch version: \", torch.__version__)\n",
        "print(\"CUDA version: \", torch.version.cuda)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, cv2\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eG8mV22MC_o-"
      },
      "outputs": [],
      "source": [
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
        "from detectron2.modeling import build_model, build_roi_heads\n",
        "from detectron2.config import get_cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7unkuuiqLdqd"
      },
      "outputs": [],
      "source": [
        "# Continuation Training but with a scheduler for optimization\n",
        "\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"fiftyone_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "# Point to the saved checkpoint from the previous training session\n",
        "\n",
        "\n",
        "# cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Gamma_office_Dataset/Weights_1/model_final.pth\"\n",
        "cfg.MODEL.WEIGHTS = \"/run/user/1000/gvfs/google-drive:host=gmail.com,user=omnidox05/0AI-koVAbJ8KdUk9PVA/1-2ZZmoG4LOv52yActwwW1J04u1OXIDDh/1-4Cy-PP5dxsMACkBWclLG7-S9yOYfvHr/1jQm__EcHNAU-mw6peloqp4_-4wnyM3Fm/1-R2-ChXwMskc1ZAhz-V3zcV1DYpNjx49\"\n",
        "\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.004\n",
        "cfg.SOLVER.MAX_ITER = 40000\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "# cfg.SOLVER.WARMUP_ITERS = 2000\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80\n",
        "# cfg.OUTPUT_DIR = \"/content/drive/MyDrive/Gamma_office_Dataset/Weights_1\"\n",
        "\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 2400\n",
        "\n",
        "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "# trainer = DefaultTrainer(cfg)\n",
        "# trainer.resume_or_load(resume=False)\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lybsyJZIM9t",
        "outputId": "e3c3ee12-4074-4e88-ba05-87d1fdf78de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model was trained for 39999 iterations.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Load the model checkpoint\n",
        "checkpoint = torch.load(os.path.join(cfg.OUTPUT_DIR, \"/run/user/1000/gvfs/google-drive:host=gmail.com,user=omnidox05/0AI-koVAbJ8KdUk9PVA/1-2ZZmoG4LOv52yActwwW1J04u1OXIDDh/1-4Cy-PP5dxsMACkBWclLG7-S9yOYfvHr/1jQm__EcHNAU-mw6peloqp4_-4wnyM3Fm/1-R2-ChXwMskc1ZAhz-V3zcV1DYpNjx49\"))\n",
        "\n",
        "# Extract the number of iterations\n",
        "iterations = checkpoint['iteration']\n",
        "\n",
        "print(f\"The model was trained for {iterations} iterations.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVo8EqIarV1Y",
        "outputId": "43850582-9900-4b35-d346-2cd0da9e6802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[07/26 11:03:14 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /run/user/1000/gvfs/google-drive:host=gmail.com,user=omnidox05/0AI-koVAbJ8KdUk9PVA/1-2ZZmoG4LOv52yActwwW1J04u1OXIDDh/1-4Cy-PP5dxsMACkBWclLG7-S9yOYfvHr/1jQm__EcHNAU-mw6peloqp4_-4wnyM3Fm/1-R2-ChXwMskc1ZAhz-V3zcV1DYpNjx49 ...\n"
          ]
        }
      ],
      "source": [
        "# cfg = get_cfg()\n",
        "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "# cfg.merge_from_file(\"/content/drive/MyDrive/detectron/output/content/output/config.yml\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(\"/run/user/1000/gvfs/google-drive:host=gmail.com,user=omnidox05/0AI-koVAbJ8KdUk9PVA/1-2ZZmoG4LOv52yActwwW1J04u1OXIDDh/1-4Cy-PP5dxsMACkBWclLG7-S9yOYfvHr/1jQm__EcHNAU-mw6peloqp4_-4wnyM3Fm/1-R2-ChXwMskc1ZAhz-V3zcV1DYpNjx49\")  # path to the model we just trained\n",
        "predictor = DefaultPredictor(cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1p0C6SEyvJz",
        "outputId": "e8963fce-d0c6-4bbb-fae6-5bbfe98e955e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importing samples...\n",
            " 100% |███████████████| 7339/7339 [224.8ms elapsed, 0s remaining, 32.6K samples/s]      \n",
            "Import complete\n"
          ]
        }
      ],
      "source": [
        "# import fiftyone as fo\n",
        "\n",
        "\n",
        "# export_dir = \"/content/drive/MyDrive/Alpha_dataset_02\"\n",
        "export_dir = \"alpha_dataset_02/Alpha_dataset_02\"\n",
        "\n",
        "# Import the dataset\n",
        "imported_dataset = fo.Dataset.from_dir(\n",
        "    dataset_dir=export_dir,\n",
        "    dataset_type=fo.types.FiftyOneDataset,\n",
        "    name=\"imported_dataset_name\",\n",
        "    overwrite=True  # Overwrite existing dataset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cgND9DV97y5",
        "outputId": "50a3739d-6be7-4796-dc92-8839994048a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Adhesive tape', 'Apple', 'Artichoke', 'Ball', 'Balloon', 'Banana', 'Beer', 'Bell pepper', 'Belt', 'Book', 'Boot', 'Bottle', 'Bowl', 'Box', 'Broccoli', 'Cake', 'Calculator', 'Camera', 'Candle', 'Carrot', 'Cheese', 'Chopsticks', 'Clock', 'Clothing', 'Coin', 'Computer mouse', 'Cookie', 'Cucumber', 'Dice', 'Doughnut', 'Drinking straw', 'Flower', 'Flying disc', 'Garden Asparagus', 'Glove', 'Grape', 'Handbag', 'Hat', 'High heels', 'Juice', 'Knife', 'Lemon', 'Mobile phone', 'Muffin', 'Mug', 'Mushroom', 'Orange', 'Oyster', 'Pastry', 'Peach', 'Pear', 'Pen', 'Pencil case', 'Plastic bag', 'Platter', 'Popcorn', 'Potato', 'Pretzel', 'Radish', 'Remote control', 'Roller skates', 'Ruler', 'Saucer', 'Scarf', 'Scissors', 'Shirt', 'Shorts', 'Skirt', 'Sock', 'Spoon', 'Stapler', 'Strawberry', 'Swimwear', 'Tablet computer', 'Teddy bear', 'Tie', 'Towel', 'Watch', 'Wine', 'Zucchini']\n"
          ]
        }
      ],
      "source": [
        "# Get the list of classes for the \"ground_truth\" field\n",
        "GT_Classes = imported_dataset.distinct(\"ground_truth.detections.label\")\n",
        "\n",
        "# Print the classes\n",
        "print(GT_Classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F6ANX8WxvjrF"
      },
      "outputs": [],
      "source": [
        "classes = ['Apple', 'Orange', 'Peach', 'Strawberry', 'Grape', 'Pear', 'Lemon', 'Banana',\n",
        "'Bottle', 'Beer', 'Juice', 'Wine',\n",
        "'Carrot', 'Bell pepper', 'Cucumber', 'Broccoli', 'Garden Asparagus', 'Zucchini', 'Radish', 'Artichoke', 'Mushroom', 'Potato',\n",
        "'Pretzel', 'Popcorn', 'Muffin', 'Cheese', 'Cake', 'Cookie', 'Pastry', 'Doughnut',\n",
        "'Pen', 'Adhesive tape', 'Pencil case', 'Stapler', 'Scissors', 'Ruler',\n",
        "'Ball', 'Balloon', 'Dice', 'Flying disc', 'Teddy bear',\n",
        "'Platter', 'Bowl', 'Knife', 'Spoon', 'Saucer', 'Chopsticks', 'Drinking straw', 'Mug',\n",
        "'Glove', 'Belt', 'Sock', 'Tie', 'Watch', 'Computer mouse', 'Coin', 'Calculator', 'Box', 'Boot', 'Towel', 'Shorts', 'Swimwear',\n",
        "'Shirt', 'Clock', 'Hat', 'Scarf', 'Roller skates', 'Skirt', 'Mobile phone',\n",
        "'Plastic bag', 'High heels', 'Handbag', 'Clothing', 'Oyster', 'Tablet computer', 'Book', 'Flower', 'Candle', 'Camera', 'Remote control']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDToNcb2vjrF",
        "outputId": "06a00cad-db3e-4caf-f742-50b5dd1f9725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes:  80\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(classes)\n",
        "print(\"Number of classes: \", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4LR6Ml9z92A7"
      },
      "outputs": [],
      "source": [
        "# Empty Polygon Error correction for fiftyone.\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def get_fiftyone_dicts(samples, classes):\n",
        "    samples.compute_metadata()\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for sample in samples.select_fields([\"id\", \"filepath\", \"metadata\", \"ground_truth\"]):\n",
        "        height = sample.metadata[\"height\"]\n",
        "        width = sample.metadata[\"width\"]\n",
        "        record = {}\n",
        "        record[\"file_name\"] = sample.filepath\n",
        "        record[\"image_id\"] = sample.id\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        objs = []\n",
        "        for det in sample.ground_truth.detections:\n",
        "            if det.label in classes:\n",
        "                tlx, tly, w, h = det.bounding_box\n",
        "                bbox = [int(tlx*width), int(tly*height), int(w*width), int(h*height)]\n",
        "                fo_poly = det.to_polyline()\n",
        "                if fo_poly.points:\n",
        "                    poly = [(x*width, y*height) for x, y in fo_poly.points[0]]\n",
        "                    poly = [p for x in poly for p in x]\n",
        "                    if len(poly) >= 6:  # Check if the coordinates are sufficient to form a polygon\n",
        "                        obj = {\n",
        "                            \"bbox\": bbox,\n",
        "                            \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                            \"segmentation\": [poly],\n",
        "                            \"category_id\": classes.index(det.label),\n",
        "                        }\n",
        "                        objs.append(obj)\n",
        "\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "\n",
        "    return dataset_dicts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cYJ87SdUB-z9"
      },
      "outputs": [],
      "source": [
        "# Sets up Catalog Data for default fiftyone structured files\n",
        "\n",
        "\n",
        "for d in [\"train\", \"val\"]:\n",
        "    view = imported_dataset.match_tags(d)\n",
        "    DatasetCatalog.register(\"fiftyone_\" + d, lambda view=view: get_fiftyone_dicts(view, classes))\n",
        "    MetadataCatalog.get(\"fiftyone_\" + d).set(thing_classes=classes)\n",
        "\n",
        "metadata = MetadataCatalog.get(\"fiftyone_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "x9YH6TjPq228"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ndhBSsc4q0pk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3tddKefcknb9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import requests\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3zuwo9IZ09wq"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import gzip\n",
        "import base64\n",
        "\n",
        "\n",
        "def classify_objects(objects_list):\n",
        "    for object_info in objects_list:\n",
        "        class_name = object_info[\"class_name\"]\n",
        "        object_id = object_info[\"object_id\"]\n",
        "        segmentation = object_info[\"segmentation\"]\n",
        "        box = object_info[\"box\"]\n",
        "\n",
        "        scores = {\n",
        "            category: score_dict[category].get(class_name, 0) * 100\n",
        "            for category in score_dict\n",
        "        }\n",
        "\n",
        "        if all(score == 0 for score in scores.values()):\n",
        "            scores[\"Misc\"] = 100\n",
        "\n",
        "        print(f\"Class Name: {class_name}\")\n",
        "        print(f\"Object ID: {object_id}\")\n",
        "        print(f\"Box: {box}\")\n",
        "        print(f\"Segmentation: {segmentation}\")\n",
        "        for category, score in scores.items():\n",
        "            if score != 0:\n",
        "                print(f\"{category}: {score}%\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "    #     # Convert the numpy array to bytes\n",
        "    #     segmentation_bytes = segmentation.cpu().numpy().tobytes()\n",
        "\n",
        "    #     # Encode the bytes to a base64 string\n",
        "    #     segmentation_b64 = base64.b64encode(segmentation_bytes).decode('utf-8')\n",
        "\n",
        "    #     payload = {\n",
        "    #         \"class_name\": class_name,\n",
        "    #         \"object_id\": object_id,\n",
        "    #         \"box\": box,\n",
        "    #         \"segmentation\": segmentation_b64,\n",
        "    #         \"shape\": segmentation.shape\n",
        "    #     }\n",
        "\n",
        "    #     json_data = json.dumps(payload)\n",
        "    #     compressed_data = gzip.compress(bytes(json_data, 'utf-8'))\n",
        "    #     headers = {'Content-Encoding': 'gzip'}\n",
        "\n",
        "    #     response = requests.post(url, data=compressed_data, headers=headers)\n",
        "    #     print(\"Response: \", response.json())\n",
        "\n",
        "    # print(\"---------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eVWcewITr5df"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# import json\n",
        "\n",
        "# # define your Flask-ngrok url here\n",
        "# url = \"http://montclair-object-detector.ngrok.app/\"\n",
        "\n",
        "# def classify_objects(objects_list):\n",
        "#     for object_info in objects_list:\n",
        "#         class_name = object_info[\"class_name\"]\n",
        "#         object_id = object_info[\"object_id\"]\n",
        "#         segmentation = object_info[\"segmentation\"]\n",
        "#         box = object_info[\"box\"]\n",
        "\n",
        "#         scores = {\n",
        "#             category: score_dict[category].get(class_name, 0) * 100\n",
        "#             for category in score_dict\n",
        "#         }\n",
        "\n",
        "#         if all(score == 0 for score in scores.values()):\n",
        "#             scores[\"Misc\"] = 100\n",
        "\n",
        "#         print(f\"Class Name: {class_name}\")\n",
        "#         print(f\"Object ID: {object_id}\")\n",
        "#         print(f\"Box: {box}\")\n",
        "#         print(f\"Segmentation: {segmentation}\")\n",
        "#         for category, score in scores.items():\n",
        "#             if score != 0:\n",
        "#                 print(f\"{category}: {score}%\")\n",
        "#         print(\"\\n\")\n",
        "\n",
        "#         # Sending POST request to the Flask server\n",
        "#         payload = {\n",
        "#             \"class_name\": class_name,\n",
        "#             \"object_id\": object_id,\n",
        "#             \"box\": box,\n",
        "#             \"segmentation\": segmentation.cpu().numpy().tolist()  # Convert to list here\n",
        "#         }\n",
        "\n",
        "#         response = requests.post(url, json=payload)\n",
        "#         print(\"Response: \", response.json())\n",
        "\n",
        "#     print(\"---------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mG0ddVMDDp19"
      },
      "outputs": [],
      "source": [
        "def generate_objects_list(outputs, cfg):\n",
        "    instances = outputs[\"instances\"]\n",
        "\n",
        "    metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
        "    class_catalog = metadata.thing_classes\n",
        "\n",
        "    return [{\n",
        "        \"class_name\": class_catalog[instances.pred_classes[idx]],\n",
        "        \"object_id\": idx,\n",
        "        \"segmentation\": instances.pred_masks[idx],\n",
        "        \"box\": coordinates.tolist()\n",
        "    } for idx, coordinates in enumerate(instances.pred_boxes.tensor)]\n",
        "\n",
        "\n",
        "score_dict = {\n",
        "    \"Fruit\": {\n",
        "        'Apple': 0.98, 'Orange': 0.46, 'Peach': 0.62, 'Strawberry': 0.92,\n",
        "        'Grape': 0.96, 'Pear': 0.91, 'Banana': 0.95, 'Carrot': 0.88,\n",
        "        'Pepper': 0.82, 'Cucumber': 0.91, 'Zucchini': 0.97,\n",
        "        'Radish': 0.76, 'Artichoke': 0.7, 'Cheese': 0.75\n",
        "    },\n",
        "    \"Drink\": {\n",
        "        'Bottle': 0.66, 'Beer': 0.82, 'Juice': 0.73, 'Wine': 0.84,\n",
        "        'Mug': 0.96, 'Spoon': 0.46, 'Saucer': 0.46, 'Hat': 0.46,\n",
        "    },\n",
        "    \"Vegetable\": {\n",
        "        'Strawberry': 0.7, 'Banana': 0.76, 'Carrot': 0.97, 'Pepper': 0.7,\n",
        "        'Cucumber': 0.88, 'Broccoli': 0.82, 'Garden Asparagus': 0.91,\n",
        "        'Zucchini': 0.89, 'Artichoke': 0.75, 'Mushroom': 0.76,\n",
        "        'Potato': 0.91, 'Cheese': 0.7\n",
        "    },\n",
        "    \"Snacks\": {'Apple': 0.69, 'Banana': 0.78, 'Popcorn': 0.89, 'Muffin': 0.84},\n",
        "    \"Stationery\": {\n",
        "        'Pen': 0.87, 'Adhesive tape': 0.67, 'Stapler': 0.67,\n",
        "        'Ruler': 0.81, 'Calculator': 0.58, 'Box': 0.96, 'Clock': 0.67\n",
        "    },\n",
        "    \"Toys\": {'Ball': 0.75, 'Flying disc': 0.46, 'Teddy bear': 0.87},\n",
        "    \"Tableware\": {\n",
        "        'Orange': 0.83, 'Plate': 0.64, 'Knife': 0.46, 'Spoon': 0.46, 'Saucer': 0.46, 'Chopsticks': 0.58\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Y35ohS-DD29p"
      },
      "outputs": [],
      "source": [
        "# def classify_objects(objects_list):\n",
        "#     for object_info in objects_list:\n",
        "#         class_name = object_info[\"class_name\"]\n",
        "#         object_id = object_info[\"object_id\"]\n",
        "#         segmentation = object_info[\"segmentation\"]\n",
        "#         box = object_info[\"box\"]\n",
        "\n",
        "#         scores = {\n",
        "#             category: score_dict[category].get(class_name, 0) * 100\n",
        "#             for category in score_dict\n",
        "#         }\n",
        "\n",
        "#         if all(score == 0 for score in scores.values()):\n",
        "#             scores[\"Misc\"] = 100\n",
        "\n",
        "#         print(f\"Class Name: {class_name}\")\n",
        "#         print(f\"Object ID: {object_id}\")\n",
        "#         print(f\"Box: {box}\")\n",
        "#         print(f\"Segmentation: {segmentation}\")\n",
        "#         for category, score in scores.items():\n",
        "#             if score != 0:\n",
        "#                 print(f\"{category}: {score}%\")\n",
        "#         print(\"\\n\")\n",
        "\n",
        "#     print(\"---------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IGOUBGv08Hyw",
        "outputId": "4fd471de-7d73-456d-dd6b-d47a722d0c54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rafaelhidalgo/git_projects/local_detectron/detectron_env/lib/python3.10/site-packages/detectron2/layers/wrappers.py:127: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
            "  x = F.conv2d(\n",
            "/home/rafaelhidalgo/git_projects/local_detectron/detectron_env/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m out \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mdraw_instance_predictions(outputs[\u001b[39m\"\u001b[39m\u001b[39minstances\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     23\u001b[0m \u001b[39m# Display the resulting frame\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39mWebcam\u001b[39;49m\u001b[39m'\u001b[39;49m, out\u001b[39m.\u001b[39;49mget_image()[:, :, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     26\u001b[0m \u001b[39m# Break the loop on 'q' key press\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Initialize the webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, img = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Make the predictions\n",
        "    outputs = predictor(img)\n",
        "    objects_list = generate_objects_list(outputs, cfg)\n",
        "    classify_objects(objects_list)\n",
        "\n",
        "    v = Visualizer(img[:, :, ::-1],\n",
        "                 metadata=metadata,\n",
        "                 scale=1.2)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Webcam', out.get_image()[:, :, ::-1])\n",
        "\n",
        "    # Break the loop on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything is done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
